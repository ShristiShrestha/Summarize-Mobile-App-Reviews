{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "753478b3-b536-4064-b2a8-199cdaac3bc3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef032607-c080-46c7-a8bf-0067a7efe57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run lib.ipynb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c80f59f3-03bc-4ec6-b8da-ba360e037c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_apps = {\n",
    "    \"ridehailing\": [\"uber\", \"lyft\"],\n",
    "    \"dating\": [\"tinder\", \"bumble\"],\n",
    "    \"investing\": [\"robinhood\", \"acorn\"],\n",
    "    \"mentalhealth\": [\"calm\", \"headspace\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8b77d50-4a1a-4322-b1e7-66d762f88ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_apps_df = {}\n",
    "domains_apps_df_stats = []\n",
    "\n",
    "for domain, apps in domains_apps.items():\n",
    "    for app in apps:\n",
    "        input_file = f\"./data/reviews/raw/{domain}/{app}.csv\"\n",
    "        df = pd.read_csv(input_file)\n",
    "        domains_apps_df[f\"{domain}_{app}\"] = df\n",
    "        domains_apps_df_stats.append((domain, app, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8711f148-7933-4247-8e90-5e6edf9883c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>app</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ridehailing</td>\n",
       "      <td>uber</td>\n",
       "      <td>5018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ridehailing</td>\n",
       "      <td>lyft</td>\n",
       "      <td>8662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dating</td>\n",
       "      <td>tinder</td>\n",
       "      <td>5004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dating</td>\n",
       "      <td>bumble</td>\n",
       "      <td>3245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>investing</td>\n",
       "      <td>robinhood</td>\n",
       "      <td>5009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>investing</td>\n",
       "      <td>acorn</td>\n",
       "      <td>3843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>calm</td>\n",
       "      <td>5004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>headspace</td>\n",
       "      <td>4940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         domain        app  count\n",
       "0   ridehailing       uber   5018\n",
       "1   ridehailing       lyft   8662\n",
       "2        dating     tinder   5004\n",
       "3        dating     bumble   3245\n",
       "4     investing  robinhood   5009\n",
       "5     investing      acorn   3843\n",
       "6  mentalhealth       calm   5004\n",
       "7  mentalhealth  headspace   4940"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(domains_apps_df_stats, columns=[\"domain\", \"app\", \"count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62395cf0-dffc-4543-afb9-ea53c2cc3e3b",
   "metadata": {},
   "source": [
    "## Apply preprocessing at review/sentence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d40a4809-ce76-4eea-9335-69aa3b7a4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "lng = \"en\"\n",
    "lng_threshold = 0.85\n",
    "\n",
    "def check_lng_label(row, lng=[\"en\"]):\n",
    "    items = row[\"english score\"]\n",
    "    row[\"isEnglish\"] = False\n",
    "\n",
    "    try:\n",
    "        if isinstance(items, str):\n",
    "            items = items.split(\",\")\n",
    "            lng_check = items[0] in lng\n",
    "            score_check = float(items[1]) >= lng_threshold\n",
    "            row[\"isEnglish\"] = lng_check and score_check\n",
    "    except Exception as e:\n",
    "        print(\"error lng\" , row[\"app\"], row[\"uuid\"],  row[\"title\"], row[\"review\"] , e)\n",
    "    \n",
    "    return row\n",
    "\n",
    "def check_empty(arr):\n",
    "    return [item for item in arr if len(item) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "984f178e-6930-4014-b01b-8aba5c2e1a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(row, col=\"review\", show_logs = False):\n",
    "    text = row[col]\n",
    "    preprend = \"\" if col == \"review\" else f\"{col}_\" # distinguish review cleaning and sentences cleaning\n",
    "    row[preprend + \"cleaned\"] = \"\"\n",
    "    row[preprend + \"tokenized\"] = \"\"\n",
    "    row[preprend + \"lemma\"] = \"\"\n",
    "    row[preprend + \"cleaned length\"] = 0\n",
    "    row[preprend + \"tokenized length\"] = 0\n",
    "    row[preprend + \"lemma length\"] = 0\n",
    "    row[preprend +  \"english score\"] = False\n",
    "\n",
    "    row_uuid = preprend +  \"uuid\"\n",
    "    \n",
    "    if row_uuid not in row and col != \"review\":\n",
    "        row[row_uuid] = str(uuid.uuid4())\n",
    "        \n",
    "    if pd.isnull(text):\n",
    "        return row  \n",
    "    \n",
    "    detected = check_lang(text, 'en', True, 0.85) # text, language, should check threshold, threshold\n",
    "    lng = detected[\"language\"]\n",
    "    score = detected[\"score\"]\n",
    "\n",
    "    if show_logs:\n",
    "        print(lng, score, text)\n",
    "    row[preprend + \"english score\"] = \",\".join([lng, str(score)])\n",
    "    row[preprend + \"isEnglish\"] = lng == \"en\" and score >= lng_threshold\n",
    "    \n",
    "    cleaned_text = clean_text(text.lower())\n",
    "    tokens = nltk_tokenize(cleaned_text)\n",
    "    tokens = remove_punctuation(tokens)\n",
    "    tokens = remove_non_alphabetic(tokens)\n",
    "    row[preprend + \"cleaned\"] = \",\".join(tokens)\n",
    "    row[preprend + \"cleaned length\"] = len(tokens)\n",
    "\n",
    "    \n",
    "    tokens = check_empty(nltk_remove_stopwords(tokens, custom_stop_words))\n",
    "    row[preprend + \"tokenized\"] = \",\".join(tokens)\n",
    "    \n",
    "    lemma = check_empty(nltk_lemmatize_post_tag_rev_words(tokens).split(\",\"))\n",
    "\n",
    "    if show_logs:\n",
    "        print(\"cleaned: \", tokens, \"\\nlemma\", lemma)\n",
    "        \n",
    "    row[preprend + \"lemma\"] = \",\".join(lemma)\n",
    "    \n",
    "    row[preprend + \"tokenized length\"] = len(tokens)\n",
    "    row[preprend + \"lemma length\"] = len(lemma)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b65798b8-de31-4a46-91d1-95856607f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_into_sentences(df, review_index):\n",
    "    records = df.to_records(index=False)\n",
    "    app_sents = []\n",
    "    cols = df.columns\n",
    "    \n",
    "    for row in records:\n",
    "        row_items = []\n",
    "        row_items.extend(row)\n",
    "        \n",
    "        row_review = row[review_index]\n",
    "\n",
    "        if not pd.isnull(row_review):\n",
    "            print(row_review)\n",
    "            row_rev_sents = nltk.sent_tokenize(row_review)\n",
    "            sents_items = []\n",
    "            \n",
    "            # loop through each sentence\n",
    "            for sent in row_rev_sents:\n",
    "                sent_items = []\n",
    "                sent_items.extend(row_items) # add all columns from previous reviews df\n",
    "                sent_items.append(sent) # append new col (sent)\n",
    "\n",
    "                # all cols from previous reviews df plus 'sent'\n",
    "                sents_items.append(sent_items)\n",
    "\n",
    "                # app sent. level info to app df\n",
    "                app_sents.append(sent_items)\n",
    "                \n",
    "    new_cols = []\n",
    "    new_cols.extend(list(cols))\n",
    "    new_cols.append(\"sent\")\n",
    "    sents_df = pd.DataFrame(app_sents, columns=new_cols)\n",
    "    return sents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d08a8fa-f5fb-491d-abe4-4b7208baecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply review level preprocessing\n",
    "\n",
    "for key, df in domains_apps_df.items():\n",
    "    df = df.apply(lambda row: preprocess(row), axis=1)\n",
    "    domains_apps_df[key] = df\n",
    "    # df.to_csv(f\"./data/{key}.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bde4b5-81d5-41f6-9143-d1713fd12448",
   "metadata": {},
   "source": [
    "## Apply relevant filters \n",
    "\n",
    "- **recency**: reviews posted after 2020\n",
    "- **language**: reviews must be in English language\n",
    "- **review length**: reviews' lemmatized length must be > 10 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d54418-3c7f-4e63-b5f0-4b3db1d478ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Filter reviews posted before 2020 from analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580986b-f8eb-4463-a17f-5aaea5d70a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in domains_apps_df.items():\n",
    "    df['date'] = pd.to_datetime(df['date'])    \n",
    "    df = df[df['date'].dt.year > 2020]\n",
    "    domains_apps_df[key] = df\n",
    "    print(key, len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838ce791-2119-4c98-890d-ead6be737f5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. Filter reviews with language label other than English \n",
    "### 3. Filter reviews with length < 10 words from analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06390d74-3d7d-4ba0-874f-67d1223f500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in domains_apps_df.items():\n",
    "    df = df[df['isEnglish'] == True]\n",
    "    df = df[df['lemma length'] >= 10]\n",
    "    domains_apps_df[key] = df\n",
    "    print(key, len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9c630-9859-4bc7-82f3-9a09b0ca5f17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sample size for summary generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8f334a-f412-45c1-a089-422dab0b4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain, appname, total reviews, 1, 2, 3, 4, 5\n",
    "apps_count_stats = []\n",
    "\n",
    "for key, df in domains_apps_df.items():\n",
    "    domain_app = key.split(\"_\")\n",
    "    app_rate_lens = [domain_app[0], domain_app[1], len(df)] \n",
    "    \n",
    "    for rate in range(1, 6):\n",
    "        rate_df = df[df[\"rating\"] == rate]\n",
    "        app_rate_lens.append(len(rate_df))\n",
    "        \n",
    "    apps_count_stats.append(app_rate_lens)\n",
    "\n",
    "apps_count_stats_df = pd.DataFrame(apps_count_stats, columns=[\"domain\", \"app\", \"total\",  \"#1\", \"#2\", \"#3\", \"#4\", \"#5\"])\n",
    "apps_count_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b397f-dbd0-42a1-92b6-e82829e57410",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 353\n",
    "\n",
    "'''\n",
    "sample size: 355\n",
    "Margin of error: 5.24%\n",
    "'''\n",
    "\n",
    "def sample_size_rating(row):\n",
    "    total = row[\"total\"]\n",
    "    samples = 0\n",
    "    for i in range(1, 6):\n",
    "        rating_count = row[\"#\"+str(i)]\n",
    "        prop_count = int(total_samples * float(rating_count/total))\n",
    "        rate_size = prop_count\n",
    "        row[\"#\"+str(i)+\"_samples\"] = rate_size\n",
    "        samples += rate_size\n",
    "    row[\"#samples\"] = samples\n",
    "    return row\n",
    "\n",
    "count_stats = apps_count_stats_df.apply(lambda row:sample_size_rating(row), axis=1)\n",
    "count_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac34eec-374f-4e81-897d-373be9d1846a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Compute TF.IDF for estimate relevant score for the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d9e6f4ad-bc74-42ba-b9ea-b60985bcd3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix (corpus_size, num_features) : term frequency of unique words in each document\n",
    "# df also known as document frequency (num_features) : counts number of doc that contains the given word\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class TfidfTransformer:\n",
    "    def __init__(self, num_unique_words, corpus_size):\n",
    "        self.num_unique_words = num_unique_words\n",
    "        self.corpus_size = corpus_size # size of corpus\n",
    "\n",
    "    def transform(self, matrix, df):\n",
    "        tf = matrix / self.num_unique_words # normalize term frequency by the number of unique words in the corpus\n",
    "        idf = np.log(self.corpus_size / df)\n",
    "        tf_idf = tf * idf\n",
    "        return tf_idf\n",
    "        \n",
    "def compute_tfidf(uuids_sents, num_reviews = None):\n",
    "    spaced_sents_only = [item[1] for item in uuids_sents]\n",
    "    spaced_sents_uuids_only = [item[0] for item in uuids_sents]\n",
    "    num_reviews = num_reviews if num_reviews is not None else len(spaced_sents_only)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(norm=None) # # do not apply L2 normalization to TF-IDF scores\n",
    "    tfidf_matrix = vectorizer.fit_transform(spaced_sents_only)\n",
    "    \n",
    "    combined_words = \" \".join(spaced_sents_only)\n",
    "\n",
    "    if len(combined_words) > 0:\n",
    "        corpus_size = len(combined_words.split(\" \")) # number of words\n",
    "        num_unique_words = tfidf_matrix.getnnz(axis=1).sum()\n",
    "        hybrid_transformer = TfidfTransformer(num_unique_words, corpus_size)\n",
    "        doc_freq = np.array((tfidf_matrix != 0).sum(axis=0)).flatten()\n",
    "        sentence_scores = hybrid_transformer.transform(tfidf_matrix, doc_freq)\n",
    "        sentence_scores = np.array(sentence_scores)\n",
    "        return sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6d414463-dade-4255-ba0c-db870fbb03c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute avg score of review from its sentences\n",
    "\n",
    "def assign_zero_score(row):\n",
    "    score = row[\"sent_hybrid tfidf score\"]\n",
    "    row[\"sent_hybrid tfidf score\"] = score if not pd.isnull(score) else 0\n",
    "    return row\n",
    "\n",
    "def avg_sents_scores(review_id, _df):\n",
    "    df = _df[_df[\"uuid\"] == review_id]\n",
    "    avg_sents_score = np.mean(df[\"sent_hybrid tfidf score\"])\n",
    "    return avg_sents_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "78547f45-0e89-48ed-b255-d201b2ee52f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store reviews split into sentences as a separate dataframe\n",
    "# apply preprocessing and compute TF.IDF score for each sentence\n",
    "# use aggregate of sentence level scores to compute average review TF.IDF score\n",
    "\n",
    "domains_apps_sents_df = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4255fd2-a2aa-43e3-bb57-78d324241494",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, reviews_df in domains_apps_df.items():\n",
    "    # break reviews into sentences\n",
    "    df = break_into_sentences(reviews_df, 1)\n",
    "    # apply preprocessing at sentence level\n",
    "    df = df.apply(lambda row: preprocess(row, \"sent\"), axis=1)\n",
    "    domains_apps_sents_df[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf5520a-92fa-444b-b7e5-e1fa7e79a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_sents_scores = {}\n",
    "\n",
    "for key, reviews_df in domains_apps_sents_df.items():\n",
    "    # break reviews into sentences\n",
    "    df = break_into_sentences(reviews_df, 1)\n",
    "    # apply preprocessing at sentence level\n",
    "    df = df.apply(lambda row: preprocess(row, \"sent\"), axis=1)\n",
    "    \n",
    "    uuids = df[\"sent_uuid\"].tolist()\n",
    "    lemma_reviews_sents = df[\"sent_lemma\"].tolist()\n",
    "    spaced_non_empty_sents = []\n",
    "    for sent_id, sent in zip(uuids, lemma_reviews_sents):\n",
    "        if isinstance(sent, str) and len(sent) > 0:\n",
    "            sent_spaced = re.sub(\",\" , \" \", sent)\n",
    "            spaced_non_empty_sents.append((sent_id, sent_spaced))\n",
    "    \n",
    "    if len(lemma_reviews_sents) != len(spaced_non_empty_sents):\n",
    "        print(\"sentences filtered umatched: \", len(lemma_reviews_sents), len(spaced_non_empty_sents))\n",
    "        \n",
    "    sentence_scores = compute_tfidf(spaced_non_empty_sents)\n",
    "    for id, item in enumerate(spaced_non_empty_sents):\n",
    "        sent_score = sentence_scores[id]\n",
    "        sent_id = item[0]\n",
    "        sent = item[1]\n",
    "        \n",
    "        df.loc[df[\"sent_uuid\"] == sent_id, 'sent_hybrid tfidf score'] = sent_score\n",
    "        df.loc[df[\"sent_uuid\"] == sent_id, 'sent_hybrid tfidf score sentence'] = sent\n",
    "    tfidf_sents_scores[key] = {\"scores\": sentence_scores, \"input\": spaced_non_empty_sents, \"df\": df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a858223f-99f3-4b73-bd4b-dba137d76629",
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_ratings_scores = {}\n",
    "\n",
    "for app, items in tfidf_sents_scores.items():\n",
    "    df = items[\"df\"]\n",
    "    df = df.apply(lambda row: assign_zero_score(row), axis=1)\n",
    "\n",
    "    review_uuids = list(set(df[\"uuid\"].tolist()))\n",
    "    reviews_scores = {}\n",
    "\n",
    "    for rev_id in review_uuids:\n",
    "        avg_score = avg_sents_scores(rev_id, df)\n",
    "        df.loc[df[\"uuid\"] == rev_id, 'sent_avg_hybrid tfidf score'] = avg_score\n",
    "    \n",
    "    for rate in range(1, 6):\n",
    "        rate_df = df[df[\"rating\"] == rate]\n",
    "        rate_df = rate_df.sort_values(\"sent_avg_hybrid tfidf score\", ascending=False)\n",
    "            \n",
    "        if key not in apps_ratings_scores:\n",
    "            apps_ratings_scores[key] = {}\n",
    "        apps_ratings_scores[key][rate] = rate_df\n",
    "        print(key, rate, len(rate_df.groupby(\"uuid\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rf-experiment",
   "language": "python",
   "name": "rf-experiment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
